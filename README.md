# Fast and Scalable Strassenâ€™s Matrix Multiplication Using Apache Spark

This repository contains the implementation and results for our distributed version of **Strassenâ€™s Matrix Multiplication Algorithm**, optimized for **Apache Spark**. The project demonstrates how recursive matrix multiplication can be efficiently performed at scale in a distributed computing environment using metadata-driven partitioning, in-memory processing, and communication-aware design.

## ğŸ“˜ Overview

Traditional matrix multiplication has a computational complexity of **O(nÂ³)**, which becomes computationally expensive for large matrices. **Strassenâ€™s algorithm** improves this to **O(n^2.81)** using a divide-and-conquer strategy. However, implementing Strassenâ€™s algorithm in distributed systems is challenging due to its recursive nature and the overhead of data communication.

This project addresses these challenges and presents a scalable implementation on Apache Spark that:

- Reduces computation time using Strassenâ€™s method.
- Minimizes communication overhead via metadata replication and smart partitioning.
- Outperforms classical distributed libraries such as Spark MLlib for large-scale matrix sizes.

## ğŸ“Š Theoretical & Numerical Insights

- **Time Complexity**: Stark achieves a theoretical cost of **O(N^logâ‚‚(7))**, faster than the classical **O(NÂ³)** approach.
- **Memory Usage**: Grows as **3Ë¡Â·NÂ²**, where `l` is the recursion depth and `N` is the matrix size.
- **Communication Efficiency**: Achieved by controlling inter-node data transfer through recursion-aware partitioning.

### Key Observations:
- At **4096 Ã— 4096**, Stark showed a **20â€“30% performance improvement** over MLlib.
- Runtime followed a **U-shaped curve** with respect to the number of partitions: too few increases computation load; too many increases communication overhead.
- Most runtime was concentrated in the **division** and **leaf-node multiplication** stages of recursion.

## ğŸ› ï¸ Tech Stack

- **Apache Spark**
- **PySpark / Scala (depending on branch)**
- **Parquet** (for matrix storage)
- **NumPy** (for baseline comparison)

## ğŸ§ª Dataset

Randomly generated dense square matrices of dimensions:
- 512 Ã— 512
- 1024 Ã— 1024
- 2048 Ã— 2048
- 4096 Ã— 4096

These matrices are stored in Parquet format for compatibility with Spark.

